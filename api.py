"""
üöÄ API REST pour la Pr√©diction d'Attrition des Employ√©s
Utilisation: python api.py
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import pickle
import os
import google.generativeai as genai
from groq import Groq
from dotenv import load_dotenv

# Charger les variables d'environnement (.env)
load_dotenv()

# Configurer Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    try:
        genai.configure(api_key=GEMINI_API_KEY)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur config Gemini: {e}")
else:
    print("‚ö†Ô∏è Attention: GEMINI_API_KEY non trouv√© dans les variables d'environnement.")

# Configurer Groq
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
groq_client = None
if GROQ_API_KEY:
    try:
        groq_client = Groq(api_key=GROQ_API_KEY)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur config Groq: {e}")
else:
    print("‚ö†Ô∏è Attention: GROQ_API_KEY non trouv√© dans les variables d'environnement.")

app = Flask(__name__)
CORS(app)  # Permet les requ√™tes depuis le frontend

# Charger le mod√®le au d√©marrage
MODEL_PATH = 'models/attrition_model.pkl'
model = None

def load_model():
    """Charge le mod√®le entra√Æn√©"""
    global model
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå Erreur: Le mod√®le n'existe pas √† {MODEL_PATH}")
        print("üí° Lancez d'abord: python train_model.py")
        return False
    
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
    
    import time
    mod_time = os.path.getmtime(MODEL_PATH)
    time_str = time.ctime(mod_time)
    print(f"‚úÖ Mod√®le charg√© avec succ√®s!")
    print(f"üìÖ Timestamp du mod√®le: {time_str}")
    print(f"‚ò¢Ô∏è  VERSION: NUCLEAR (GradientBoosting)")
    return True

@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint pour v√©rifier que l'API fonctionne"""
    return jsonify({
        'status': 'ok',
        'message': 'API de pr√©diction d\'attrition op√©rationnelle',
        'model_loaded': model is not None
    })

@app.route('/fields', methods=['GET'])
def get_fields():
    """Retourne la liste des champs requis et leurs valeurs possibles"""
    return jsonify({
        'required_fields': {
            'Age': {'type': 'integer', 'description': '√Çge de l\'employ√©'},
            'Gender': {'type': 'string', 'options': ['Male', 'Female']},
            'MaritalStatus': {'type': 'string', 'options': ['Single', 'Married', 'Divorced']},
            'DistanceFromHome': {'type': 'integer', 'description': 'Distance du domicile en km'},
            'Education': {'type': 'integer', 'min': 1, 'max': 5, 'description': '1=Below College, 2=College, 3=Bachelor, 4=Master, 5=Doctor'},
            'EducationField': {'type': 'string', 'options': ['Life Sciences', 'Medical', 'Marketing', 'Technical Degree', 'Other']},
            'Department': {'type': 'string', 'options': ['Sales', 'Research & Development', 'Human Resources']},
            'JobRole': {'type': 'string', 'description': 'Poste de l\'employ√©'},
            'JobLevel': {'type': 'integer', 'min': 1, 'max': 5},
            'MonthlyIncome': {'type': 'integer', 'description': 'Revenu mensuel en $'},
            'TotalWorkingYears': {'type': 'integer', 'description': 'Ann√©es d\'exp√©rience totales'},
            'YearsAtCompany': {'type': 'integer', 'description': 'Ann√©es dans l\'entreprise'},
            'YearsWithCurrManager': {'type': 'integer', 'description': 'Ann√©es avec le manager actuel'},
            'YearsSinceLastPromotion': {'type': 'integer', 'description': 'Ann√©es depuis derni√®re promotion'},
            'NumCompaniesWorked': {'type': 'integer', 'description': 'Nombre d\'entreprises pr√©c√©dentes'},
            'BusinessTravel': {'type': 'string', 'options': ['Non-Travel', 'Travel_Rarely', 'Travel_Frequently']},
            'PercentSalaryHike': {'type': 'integer', 'description': 'Augmentation salariale (%) derni√®re ann√©e'},
            'StockOptionLevel': {'type': 'integer', 'min': 0, 'max': 3},
            'TrainingTimesLastYear': {'type': 'integer', 'description': 'Formations suivies l\'ann√©e derni√®re'},
            'EnvironmentSatisfaction': {'type': 'integer', 'min': 1, 'max': 4},
            'JobSatisfaction': {'type': 'integer', 'min': 1, 'max': 4},
            'WorkLifeBalance': {'type': 'integer', 'min': 1, 'max': 4},
            'JobInvolvement': {'type': 'integer', 'min': 1, 'max': 4},
            'PerformanceRating': {'type': 'integer', 'min': 3, 'max': 4}
        },
        'optional_fields': {
            'AvgWorkingHours': {'type': 'float', 'description': 'Heures moyennes travaill√©es par jour', 'default': 8.5},
            'LateArrivals': {'type': 'integer', 'description': 'Nombre de retards (arriv√©es apr√®s 9h)', 'default': 10},
            'AvgOvertime': {'type': 'float', 'description': 'Heures suppl√©mentaires moyennes par jour', 'default': 0.5},
            'AbsenceRate': {'type': 'float', 'description': 'Taux d\'absence en %', 'default': 5.0},
            'WorkHoursVariance': {'type': 'float', 'description': 'Variance des heures de travail (r√©gularit√©)', 'default': 1.0}
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """Endpoint principal pour pr√©dire l'attrition"""
    if model is None:
        return jsonify({
            'error': 'Mod√®le non charg√©',
            'message': 'Le mod√®le n\'a pas pu √™tre charg√© au d√©marrage'
        }), 500
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Donn√©es manquantes', 'message': 'Veuillez fournir les donn√©es de l\'employ√© en JSON'}), 400
        
        # Ajouter les features temporelles optionnelles par d√©faut si manquantes
        optional_time_features = {
            'AvgWorkingHours': 8.5, 'LateArrivals': 10, 'AvgOvertime': 0.5,
            'AbsenceRate': 5.0, 'WorkHoursVariance': 1.0
        }
        for feature, default_value in optional_time_features.items():
            if feature not in data:
                data[feature] = default_value
        
        employee_df = pd.DataFrame([data])
        
        prediction = model.predict(employee_df)[0]
        proba = model.predict_proba(employee_df)[0]
        
        proba_no = float(proba[0] * 100)
        proba_yes = float(proba[1] * 100)
        
        risk_level = 'low'
        if prediction == 1:
            if proba_yes > 70: risk_level = 'high'
            elif proba_yes > 50: risk_level = 'medium'
        
        recommendations = []
        if prediction == 1:
            recommendations = [
                "Organiser un entretien individuel",
                "√âvaluer les opportunit√©s de promotion",
                "Am√©liorer l'√©quilibre vie pro/perso",
                "Proposer des formations suppl√©mentaires"
            ]
        else:
            recommendations = ["Employ√© satisfait - Continuer le bon travail!"]
        
        response = {
            'prediction': {
                'will_leave': bool(prediction == 1),
                'label': 'Oui' if prediction == 1 else 'Non'
            },
            'probabilities': {
                'stay': round(proba_no, 2),
                'leave': round(proba_yes, 2)
            },
            'risk_level': risk_level,
            'recommendations': recommendations,
            'employee_data': data
        }
        
        return jsonify(response), 200
        
    except Exception as e:
        return jsonify({'error': 'Erreur lors de la pr√©diction', 'message': str(e)}), 500

@app.route('/chat', methods=['POST'])
def chat():
    """Endpoint pour le chatbot (Gemini ou Groq)"""
    data = request.get_json()
    user_message = data.get('message', '')
    provider = data.get('provider', 'gemini') # 'gemini' or 'groq'
    
    if not user_message:
        return jsonify({'reply': "Je n'ai pas compris votre message."}), 400

    employee_context = ""
    employee_data = data.get('employee_data')
    prediction_result = data.get('prediction_result')

    if employee_data:
        employee_context += f"""
    CONTEXTE PROFIL EMPLOY√â (Donn√©es du formulaire) :
    {employee_data}
    """

    if prediction_result:
        probabilities = prediction_result.get('probabilities', {})
        risk_level = prediction_result.get('risk_level', 'inconnu')
        employee_context += f"""
    R√âSULTAT DE LA PR√âDICTION ACTUELLE :
    - Risque d'Attrition : {risk_level.upper()}
    - Probabilit√© de D√©part : {probabilities.get('leave', 0)}%
    
    Utilise ces pourcentages pour justifier tes conseils.
    """

    context = f"""
    Tu es un Expert RH Analytique int√©gr√© dans un Dashboard de Pr√©diction d'Attrition.
    Ton r√¥le est d'aider l'utilisateur √† comprendre pourquoi un employ√© part, et √† simuler des sc√©narios.

    Donn√©es du Mod√®le d'Attrition (Random Forest + SMOTE) :
    - Facteurs cl√©s : TotalWorkingYears, Age, MonthlyIncome, YearsAtCompany, DistanceFromHome.

    {employee_context}

    Consignes :
    - Si une donn√©e contextuelle existe, utilise-la.
    - Sois concis, professionnel et direct.
    - R√©ponds en Fran√ßais.
    """
    
    try:
        reply = ""
        
        if provider == 'groq':
            if not groq_client:
                 return jsonify({'reply': "‚ö†Ô∏è API Key Groq manquante. Configurez GROQ_API_KEY."}), 200
            
            print("üöÄ Utilisation de Groq (Llama 3)...")
            chat_completion = groq_client.chat.completions.create(
                messages=[{'role': 'system', 'content': context}, {'role': 'user', 'content': user_message}],
                model="llama-3.3-70b-versatile",
            )
            reply = chat_completion.choices[0].message.content
            
        else: # Default to Gemini
            if not GEMINI_API_KEY:
                 return jsonify({'reply': "‚ö†Ô∏è API Key Gemini manquante."}), 200
                 
            print("‚ú® Utilisation de Gemini...")
            model = genai.GenerativeModel('gemini-robotics-er-1.5-preview')
            response = model.generate_content(f"{context}\n\nQuestion Utilisateur : {user_message}")
            reply = response.text

        return jsonify({'reply': reply})
        
    except Exception as e:
        error_msg = str(e)
        print(f"Erreur IA: {error_msg}")
        return jsonify({'reply': f"Erreur technique ({provider}) : {error_msg}"}), 200

if __name__ == '__main__':
    print("\n" + "="*60)
    print("üöÄ API DE PR√âDICTION D'ATTRITION DES EMPLOY√âS")
    print("="*60 + "\n")
    
    if not load_model():
        print("\n‚ö†Ô∏è  L'API va d√©marrer mais les pr√©dictions ne fonctionneront pas.")
    
    print("\nüì° Endpoints disponibles:")
    print("   GET  /health  - V√©rifier le statut de l'API")
    print("   POST /predict - Pr√©dire l'attrition")
    print("   POST /chat    - Discuter avec l'Assistant RH")
    
    print("\nüåê L'API d√©marre sur http://localhost:5000")
    print("="*60 + "\n")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
